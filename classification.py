# -*- coding: utf-8 -*-
"""classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RyNAL4CnHWH2EzLn-R-SzyvX-OoH4cX9
"""



"""I will start from importing several Python libraries commonly used in machine learning, particularly when working with image data and TensorFlow. Here's a breakdown of each import statement"""

import matplotlib.pyplot as plt #module, which is commonly used for creating visualizations and plots.
import numpy as np #is widely used for numerical computations in Python.
import PIL #is used for opening, manipulating, and saving image files
import tensorflow as tf #is a popular open-source machine learning framework.


import pathlib #provides an object-oriented interface for working with filesystem paths.
from tensorflow import keras #is a high-level neural networks API.
from tensorflow.keras import layers # is commonly used to define the layers of a neural network.
from tensorflow.keras.models import Sequential #is used to create a linear stack of layers for building neural network models.
import random #provides functions for generating random numbers.
import os #provides a way to interact with the operating system, such as working with files and directories
from os import listdir #is used to get the list of files and directories in a specified directory.
from matplotlib.image import imread #is used to read image files into numpy arrays.
from pathlib import Path

"""**load and explore the dataset**[Loading Dataset](https://saturncloud.io/blog/how-to-import-files-from-google-drive-to-colab/)

This line of code will initiates the process of mounting Google Drive
"""

from google.colab import drive
drive.mount('/content/gdrive')



path = "/content/gdrive/MyDrive/multi cancer/Brain tumour/Brain Cancer"

data_dir = path

"""I then converted my variable path into a pathlib.Path object and then assigning it back to the variable path.
allowing me to perform various operations related to filesystem paths, such as joining paths, accessing individual components of a path, listing files in a directory
"""



path = pathlib.Path(path)
path

data_dir = path

"""I then calculated the total number of image files within my directory"""

image_count = len(list(path.glob('*/*.jpg')))
print(image_count)

"""This path.glob will help me to retrieve specific character from my directory"""

list(path.glob('*/*.jpg'))[:5]

brain_glioma= list(path.glob('brain_glioma/*'))
brain_glioma[:5]

PIL.Image.open(str(brain_glioma[1]))

brain_glioma = list(path.glob('brain_glioma/*'))
PIL.Image.open(str(brain_glioma[0]))

brain_tumor = list(path.glob('brain_tumor/*'))
PIL.Image.open(str(brain_tumor[0]))

"""**Load data using a Keras utility**[Load and preprocess images ](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb)

I created a 4x4 grid of subplots and displays 9 randomly chosen images from the specified directory. The dimensions of each image are shown as labels on the x and y axes
"""

# Plotting 12 images to check dataset
plt.figure(figsize=(12,12))
path = "/content/gdrive/MyDrive/multi cancer/Brain tumour/Brain Cancer/brain_glioma"
for i in range(1,10):
    plt.subplot(4,4,i)
    plt.tight_layout()
    rand_img = imread(path +'/'+ random.choice(sorted(os.listdir(path))))
    plt.imshow(rand_img)
    plt.xlabel(rand_img.shape[1], fontsize = 10)#width of image
    plt.ylabel(rand_img.shape[0], fontsize = 10)#height of image

"""batch_size is set to 64, meaning that 64 images or data samples will be processed in each iteration during the training of a model.The height and width is set at 180 respectively"""

batch_size = 64
img_height = 224
img_width = 224

"""I specify that 20% of the dataset will be used for validation, with 80% used for training.

Seed=200: The random seed ensures that the split between training and validation sets is the same each time the code is run, which is critical for repeatability.

Image_size=(img_height, img_width): This field defines the size to which the image will be scaled(img_height = 180, img_width = 180).

Batch_size=batch_size: This parameter specifies the batch size for training.
"""

train_ds = tf.keras.utils.image_dataset_from_directory(
data_dir,
  validation_split=0.2,
  subset="training",
  seed=200,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="validation",
  seed=200,
  image_size=(img_height, img_width),
  batch_size=batch_size)

"""Let me print out the name of classes i have in my ds"""

class_names = train_ds.class_names

print (class_names)

"""**Visualize the data** To see resized image

The first five photographs from the first batch of the training dataset are displayed, together with the matching class labels, in a 3x3 grid of subplots that I generate. For improved visualization, the images are shown with thier axis labels.
"""

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(5):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("on")  # Set to "on" to display axis labels
    plt.xlabel("Width: {}".format(images[i].shape[1]))
    plt.ylabel("Height: {}".format(images[i].shape[0]))

"""I iterate over the batches of the training dataset (train_ds) using a loop.This will help me debugg and ensure that the data is being loaded in the expected format before training."""

for image_batch, labels_batch in train_ds:
  print(image_batch.shape)
  print(labels_batch.shape)
  break

"""I utilized caching to compress the massive datasets into memory, and prefetching will aid in overlapping the loading of data and model training, hence minimizing loading delays."""

AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

"""**Normalization the data**

This creates a Rescaling layer that will scale input values by a factor of 1./255. The purpose of this layer is to normalize pixel values in the input data. When images are represented as pixel values, they typically range from 0 to 255. Normalization is a common preprocessing step in deep learning, and dividing by 255 scales the pixel values to the range [0, 1].
"""

normalization_layer = layers.Rescaling(1./255)

"""i visualized my rescaled image to see how it looks"""

# In my train_ds rescaled dataset
for images, labels in train_ds.take(1):
    # Display the first 5 images along with their labels
    plt.figure(figsize=(10, 10))
    for i in range(5):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy())
        plt.title(f"Label: {labels[i]}")
        plt.axis("off")
    plt.show()

normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
image_batch, labels_batch = next(iter(normalized_ds))
first_image = image_batch[0]
# Notice the pixel values are now in `[0,1]`.
print(np.min(first_image), np.max(first_image))

"""# Create the **model**"""

num_classes = len(class_names)

model = Sequential([
  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(124, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes)
])

"""**Compile the** **model**"""

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

"""**Model summary**"""

model.summary()

"""**Train the model**"""

epochs=30
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)

"""**Visualize training results**"""



acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

path = "/content/gdrive/MyDrive/brain tumor/Tumor_Dataset/brain_menin/100.png"
path

img = tf.keras.utils.load_img(
    path, target_size=(img_height, img_width)
)
img_array = tf.keras.utils.img_to_array(img)
img_array = tf.expand_dims(img_array, 0) # Create a batch

predictions = model.predict(img_array)
score = tf.nn.softmax(predictions[0])

print(
    "This is an image that belongs to {} with a {:.2f} percent accuracy."
    .format(class_names[np.argmax(score)], 100 * np.max(score))
)

data_augmentation = keras.Sequential(
  [
    layers.RandomFlip("horizontal",
                      input_shape=(img_height,
                                  img_width,
                                  3)),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
  ]
)

plt.figure(figsize=(10, 10))
for images, _ in train_ds.take(1):
  for i in range(9):
    augmented_images = data_augmentation(images)
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(augmented_images[0].numpy().astype("uint8"))
    plt.axis("off")

model = Sequential([
  data_augmentation,
  layers.Rescaling(1./255),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Dropout(0.2),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes, name="outputs")
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.summary()

epochs = 20
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

training_loss = history.history['loss']
validation_loss = history.history['val_loss']

# Print the total number of training and validation losses
print("Total Training Losses:", len(training_loss))
print("Total Validation Losses:", len(validation_loss))

# Plot the training and validation losses over epochs
plt.plot(training_loss, label='Training Loss')
plt.plot(validation_loss, label='Validation Loss')
plt.legend()
plt.show()

path = "/content/gdrive/MyDrive/brain tumor/Tumor_Dataset/brain_menin/101.png"

"""This will load our image, processes it for input to a pre-trained machine learning model, makes predictions, and prints the predicted class along with its confidence level."""

img = tf.keras.utils.load_img(
  path, target_size=(img_height, img_width)
)
img_array = tf.keras.utils.img_to_array(img)
img_array = tf.expand_dims(img_array, 0) # Create a batch

predictions = model.predict(img_array)
score = tf.nn.softmax(predictions[0])

print(
    "This image most likely belongs to {} with a {:.2f} percent confidence."
    .format(class_names[np.argmax(score)], 100 * np.max(score))
)

import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing.image import ImageDataGenerator

data_dir = path

"""This will create a MobileNetV2 model for feature extraction, setting the input shape to 224x224 pixels with 3 color channels, excluding the top classification layer, and initializing the model with pre-trained weights from ImageNet.





"""

base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')

"""The  freezing  layers will retain the pre-trained weights and feature extraction capabilities of the MobileNetV2 model while training additional layers for a specific task. By freezing the initial layers, the model avoids modifying the learned representations that have already proven effective in capturing general features from a diverse set of images."""

for layer in base_model.layers:
    layer.trainable = False

num_classes = len(class_names)

model = Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0),
    tf.keras.layers.Dense(num_classes, activation='softmax')
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.summary()

epochs = 30  # You can adjust this
history = model.fit(train_ds, epochs=epochs, validation_data=val_ds)

training_loss = history.history['loss']
validation_loss = history.history['val_loss']

# Print the total number of training and validation losses
print("Total Training Losses:", len(training_loss))
print("Total Validation Losses:", len(validation_loss))

# Plot the training and validation losses over epochs
plt.plot(training_loss, label='Training Loss')
plt.plot(validation_loss, label='Validation Loss')
plt.legend()
plt.show()

tf.keras.models.save_model(model,'my_model3.hdf5')



path = "/content/gdrive/MyDrive/multi cancer/Brain tumour/Brain Cancer/brain_menin/brain_menin_0001.jpg"
path

img = tf.keras.utils.load_img(
    path, target_size=(img_height, img_width)
)
img_array = tf.keras.utils.img_to_array(img)
img_array = tf.expand_dims(img_array, 0) # Create a batch

predictions = model.predict(img_array)
score = tf.nn.softmax(predictions[0])

print(
    "This is an image that belongs to {} with a {:.2f} percent accuracy."
    .format(class_names[np.argmax(score)], 100 * np.max(score))
)